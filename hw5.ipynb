{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1tElT3FhddabqCyJKFH27rhnyXJTqrzke?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2683</td>\n",
       "      <td>333</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>2743</td>\n",
       "      <td>121</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>6572</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2915</td>\n",
       "      <td>90</td>\n",
       "      <td>8</td>\n",
       "      <td>216</td>\n",
       "      <td>11</td>\n",
       "      <td>4433</td>\n",
       "      <td>232</td>\n",
       "      <td>228</td>\n",
       "      <td>129</td>\n",
       "      <td>4019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2941</td>\n",
       "      <td>162</td>\n",
       "      <td>7</td>\n",
       "      <td>698</td>\n",
       "      <td>76</td>\n",
       "      <td>2783</td>\n",
       "      <td>227</td>\n",
       "      <td>242</td>\n",
       "      <td>148</td>\n",
       "      <td>1784</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3096</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>170</td>\n",
       "      <td>3</td>\n",
       "      <td>3303</td>\n",
       "      <td>231</td>\n",
       "      <td>202</td>\n",
       "      <td>99</td>\n",
       "      <td>5370</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2999</td>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>488</td>\n",
       "      <td>37</td>\n",
       "      <td>1532</td>\n",
       "      <td>228</td>\n",
       "      <td>225</td>\n",
       "      <td>131</td>\n",
       "      <td>2290</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1   2    3   4     5    6    7    8     9  ...  45  46  47  48  49  \\\n",
       "0  2683  333  35   30  26  2743  121  173  179  6572  ...   0   0   0   0   0   \n",
       "1  2915   90   8  216  11  4433  232  228  129  4019  ...   0   0   0   0   0   \n",
       "2  2941  162   7  698  76  2783  227  242  148  1784  ...   0   0   0   0   0   \n",
       "3  3096   60  17  170   3  3303  231  202   99  5370  ...   0   0   0   0   0   \n",
       "4  2999   66   8  488  37  1532  228  225  131  2290  ...   0   0   0   0   0   \n",
       "\n",
       "   50  51  52  53  54  \n",
       "0   0   0   0   0   2  \n",
       "1   0   0   0   0   1  \n",
       "2   0   0   0   0   2  \n",
       "3   0   0   0   0   1  \n",
       "4   0   0   0   0   2  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('forest_dataset.csv')\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 55)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = all_data[all_data.columns[-1]].values\n",
    "feature_matrix = all_data[all_data.columns[:-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_matrix, test_feature_matrix, train_labels, test_labels = train_test_split(\n",
    "    feature_matrix, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iamda\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_feature_matrix, train_labels)\n",
    "y_pred = clf.predict(test_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6075"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iamda\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='saga')\n",
    "\n",
    "# init GridSearchCV with parameters\n",
    "param_grid = {\n",
    "    'C': np.arange(1, 5),\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(clf, param_grid, n_jobs=-1, cv=5, refit=True, scoring='accuracy')\n",
    "\n",
    "search.fit(feature_matrix, labels)\n",
    "\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6419"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels, search.best_estimator_.predict(feature_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality of classification/regression by the k Nearest Neighbors method depends on several parameters:\n",
    "* the number of neighbors `n_neighbors`\n",
    "* the distance metric between objects `metric`\n",
    "* the weights of neighbors (the neighbors of the test example can enter with different weights, for example, the further the example, the less its \"voice\" is taken into account) `weights`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the `KNeighborsClassifier` on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7365"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(train_feature_matrix, train_labels)\n",
    "y_pred = clf.predict(test_feature_matrix)\n",
    "\n",
    "accuracy_score(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select the parameters of our model:\n",
    "\n",
    "* Iterate over the grid from `1` to `10` for the number of neighbors parameter\n",
    "* Also, try using different metrics: `['manhattan', 'euclidean']`\n",
    "* Try using different weight calculation strategies: `[‘uniform’, ‘distance’]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    'n_neighbors': np.arange(1, 11),\n",
    "    'metric': ['manhattan', 'euclidean'],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "}\n",
    "\n",
    "clf_grid = GridSearchCV(clf, params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "clf_grid.fit(feature_matrix, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's output the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the optimal number of neighbors found, calculate the probabilities of belonging to classes for the test sample (`.predict_proba`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_clf = KNeighborsClassifier(metric='manhattan', n_neighbors=4, weights='distance')\n",
    "optimal_clf.fit(train_feature_matrix, train_labels)\n",
    "pred_prob = optimal_clf.predict_proba(test_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique, freq = np.unique(test_labels, return_counts=True)\n",
    "freq = list(map(lambda x: x / len(test_labels),freq))\n",
    "\n",
    "pred_freq = pred_prob.mean(axis=0)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(range(1, 8), pred_freq, width=0.4, align=\"edge\", label='prediction')\n",
    "plt.bar(range(1, 8), freq, width=-0.4, align=\"edge\", label='real')\n",
    "plt.ylim(0, 0.54)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the quality of the model on the test sample? Compare it with the quality of logistic regression. Which model is better? Why? What are the pros and cons of the k Nearest Neighbors method? Plot the ROC curve for the k Nearest Neighbors method. Calculate the area under the ROC curve (AUC-ROC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(labels, clf_grid.best_estimator_.predict(feature_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Числа уверенно сообщают нам, о том что модель \"ближайших соседей\" лучше логистической регрессии. Это потому что k-NN учитывает локальную структуру данных, тогда как логистическая регрессия строит глобальную линейную границу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Плюсы и минусы метода k ближайших соседей  \n",
    "Плюсы:  \n",
    "✅ Простота реализации.  \n",
    "✅ Нет этапа обучения (ленивое обучение).  \n",
    "✅ Хорошо работает на данных с явными локальными закономерностями.  \n",
    "✅ Автоматическая адаптация к многоклассовому случаю (без явного переобучения, как в OvR/OvO).  \n",
    "  \n",
    "Минусы:  \n",
    "❌ Чувствителен к размерности данных (нужна предварительная обработка, например, PCA).  \n",
    "❌ Требует хранения всех данных (большие затраты памяти).  \n",
    "❌ Чувствителен к масштабированию признаков (нужна нормализация).  \n",
    "❌ Медленный на предсказании (особенно на больших выборках).  \n",
    "❌ Неочевидный выбор k для несбалансированных классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Бинаризация меток для OvR\n",
    "labels_test_bin = label_binarize(test_labels, classes=np.unique(labels))\n",
    "n_classes = labels_test_bin.shape[1]\n",
    "\n",
    "# Построение ROC-кривой для каждого класса (OvR)\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(labels_test_bin[:, i], pred_prob[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.5)')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('ROC-кривые для каждого класса (One-vs-Rest)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Микро-усредненный AUC-ROC (объединяет все классы)\n",
    "fpr_micro, tpr_micro, _ = roc_curve(labels_test_bin.ravel(), pred_prob.ravel())\n",
    "roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "print(f\"Micro-average AUC-ROC: {roc_auc_micro:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
